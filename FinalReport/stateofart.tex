Our project is about \textit{Question Answering}, a field of research included in \textit{Natural Language Processing} (NLP) theory. NLP mixes linguistic and computer science and is made of all kinds of automated techniques that have to deal with natural languages, such as French or English. For instance, automatic translation or text summarization are also parts of NLP.

In Natural Language Processing, sentences are often represented in a condensed and normalized form called \textit{(subject, predicate, object) triple representation}. For example, the phrase ``Fleming discovered penicillin.'' will be represented by the triple (penicillin, discoverer, Fleming). Two triples can be associated to ``The president was born in 1950 and died in 2000.'': (president, birth date, 1950) and (president, death date, 2000). This representation has been formalized into the \textit{Resource Description Framework} (RDF) model\footnote{\url{http://www.w3.org/TR/rdf11-concepts/}}. It consists of a general framework used to describe any Internet resource by sets of triples. One of our main goals is to parse questions to get their triples representation.

Many algorithms have been developed since fifty years with the objective of understanding the syntax and the semantic of sentences in order to extract (subject, predicate, object) triples. Two popular graph representations are widely used:
\begin{itemize}
 \item parse structure tree. It tries to split the sentence according to its grammatical structure.
 \item dependency tree. It reflects the grammatical relationships between words.
\end{itemize}
Existing libraries, such as \textit{NLTK}\footnote{\url{http://www.nltk.org/}} or \textit{StanfordParser}\footnote{\url{http://nlp.stanford.edu/software/lex-parser.shtml}} provide powerful tools to extract such representations.

We did not find a lot of detailed articles exposing procedures to get triples from the grammatical structure. For instance \cite{parsetree} tries to perform the extraction using the parse structure tree. However we believe the dependency tree could be more appropriate since it is more focused on the relations between the words than their roles in the sentence. Part \ref{gramap} presents an algorithm we have designed using the dependency tree representation.

We have also observed a growing use of machine learning techniques in NLP that try to automatically learn triples extraction rules instead of building intermediate grammatical representations. We will use such machine learning algorithms in parts \ref{} and \ref{}.

Finally, some existing tools are very close to our goal\footnote{\url{http://quepy.machinalis.com/}}\textsuperscript{,}\footnote{\url{http://www.ifi.uzh.ch/ddis/research/talking.html}}. They allow us to have a clear idea of the state of the art, and what performances in question answering we can expect.

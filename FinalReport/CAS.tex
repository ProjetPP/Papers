\newcommand{\CalChAS}{\text{C}\hspace{-2pt}_{\text{AL}}\hspace{-3pt}\text{C}^{\text{H}}{\hspace{-4pt}}_\text{AS}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\dd}{\mathrm{d}}


A computer algebra system (CAS) module has been added to the PPP. Its work is to compute formally mathematical expressions.

\section{Input-output}

The CAS module take as input a sentence whose string is a mathematical expression and output a resource of typed \texttt{math-latex} with two fields: one with a human readable formula and the other written in \LaTeX.

The difficulty is two decide whether a string represent a mathematical formula or not.

We use two tests. The first is a pre-treatment test. It checks whether the formula contains some substring which prove
\begin{itemize}
    \item the formula is a mathematical expression, like "sqrt", "\textbackslash"\ldots,
    \item the formula is not a mathematical expression, like "who", "where", accented character\ldots.
\end{itemize}

But that does not eliminate all natural language questions, there still are false positive. Nevertheless, this test is basic and works in the larger part of cases.

\bigskip

So there is another test which is more precise. For example, a query like "author of bli-bla" will not be excluded by the previous algorithm. Moreover we see here why we can't consider '-' as a characteristic character of mathematical formula. The method is to verify if the module apply modifications.

Is this example, the module has nothing to compute and car just rearrange terms. So "author of bli-bla" become something like "author bli of - bla" considering 'author', 'bli', 'bla' and 'of' as variable. But we observe there was no modification. To do this test, the module counts each kind of symbol (except space and some particular symbols). If there is the same quantity of each symbol, we consider there is no modifications and the module decides he was useless and returns an empty list.

\section{Structure}

To do mathematical computations, we use a specific library: Sympy\footnote{\url{http://www.sympy.org/en/index.html}}. But this library is able to analyse only the input write with the good syntax which is not intuitive and pretty complex.

To avoid arbitrary long computation, we launch Sympy evaluation in another process which has a limited memory and time.

To be usable, we define two parsers to handle other syntax: the syntax of Mathematica and another syntax we defined, which is designed to be intuitive and we named $\CalChAS$.

\section{Parsers}

\subsection{Mathematica parser}

This parser is quite simple. We use a LALR parser generated by PLY\footnote{\url{http://www.dabeaz.com/ply/}} (Python Lex Yacc). First, the input formula is parsed and transform into a tree, then, the tree is transform into a Sympy expression.

\subsection{\texorpdfstring{$\CalChAS$}{CalChAS} parser}

This syntax is more permissive. It allows arithmetic operations (division, multiplication, addition, subtraction, modulo, factorial, power) and several names for each standard function. For instance, the 
reciprocal of the hyperbolic sine can be written "argsh", "argsinh", "arcsh" etc.. So function names are matched with regular expression. For instance, the regex for the function argsinh is \begin{center}[\texttt{aA}](\texttt{r}([cg])?)?[\texttt{sS}](\texttt{in})?\texttt{h}\end{center}

The other feature we implement for flexibility is implicit multiplications. We understand "a b" as "a*b", "(a)b" as "(a)*b" and "(a)(b)" as "(a)*(b)". But "a(b)" have to remain unchanged because "a" can be a function so, "a(b)" is not "a*(b)".

This transformation is executed before the parser. The method is to launch the lexer a first time. Then we add the symbol "*" between the two symbols in every followed configurations: ")("; a ")" and a identifier; two consecutive identifiers. Thus, we generate a modified formula with explicit multiplications and we can parse this expression.

The last feature implemented to make this syntax more permissive is to extend functions which are defined on a subset of $\RR$ like $\NN$. For example, the factorial which is defined on $\NN^*$ is extended on $\CC\setminus \ZZ^{-*}$ by using the function $\Gamma$. Thus, the expression $(-1/2)!$ has a meaning.

This syntax admits notation as defined in the standard ISO 31-11.

\section{Future work}

A parser for \LaTeX expressions can be implemented. We started to write a \LaTeX parser but it was more complicated than expected and actually, it does not work for big operators like sum, product or integral.

We can also cover other mathematical fields. For instance:
\begin{itemize}
    \item probability,
    \item statistics,
    \item regression analysis,
    \item logic and set theory,
    \item discrete mathematics,
    \item sequences,
    \item plots.
\end{itemize}

We can imagine a more lenient syntax for functions which need to bound a variable when there is no ambiguities. For instance, we plan to allow "int(sin(x),0,Pi)" for "int(sin(x),x,0,Pi)" because $x$ is the only variable in this expression. If we are able to determine the list of variables, there is easy to create a new variable. That allows to define functions like $(k,n)\mapsto \binom{n}{k}$ on a larger set using a limit.

An important missing feature is the resolution of differential equations. In fact the \texttt{dsolve} function of Sympy does not work on every ODE and does not handle initial conditions. If this feature is not implemented soon, we will use the \texttt{dsolve} function of Sympy without initial conditions and determine constants with the function \texttt{solve}.

The other feature to implement, is the interpretation of mathematical queries expressed in natural language. For example, "integrate sin x dx from x=0 to pi" instead of "integrate(sin(x),x,0,pi)".
\section{Grammatical approach}

\subsection{Stanford CoreNLP}

Our work relies on the \emph{Stanford CoreNLP} library
\footnote{\url{http://nlp.stanford.edu/software/corenlp.shtml}}, developped by
the Stanford Natural Language Processing group, which include members with 
linguistics or computer science backgrounds. 

Since this library is written in Java, and our module in Python, we use a wrapper
also written in Python
\footnote{\url{https://bitbucket.org/ProgVal/corenlp-python/overview}}.

These tools provide a server running in background, which takes a character string,
and returns a dependency tree, with some additional informations on certain words.
See figure \ref{tree_before} to have an overview of such a tree, for the sentence
\emph{What is the birth date of the first president of the United States of America?}.

The nodes of this tree are words, and the arcs are dependencies. For instance,
an arc $$\texttt{president}\xrightarrow{\texttt{det}}\texttt{the}$$ means that
\emph{the} is a determiner for \emph{president}. All possible dependencies are 
described in \cite{stanfordDep}. 

Some nodes of this tree are also endowed with tags. For instance, \emph{America}
has the tag \emph{location}.


\subsection{Preprocessing}

The processing consists of a sequence of operations on the tree given by the 
\emph{Stanford CoreNLP} library. The aim is to simplify the tree, by merging the
nodes which should belong together.

The current version of the module performs two sorts of merges:
\begin{itemize}
    \item \textbf{Merge quotation nodes.} This operation merge all the nodes which
    are in a same quotation (delimited by quotation marks). It also adds the words
    of the quotations which were deleted by the \emph{Stanford CoreNLP} library
    (e.g. \emph{in}, \emph{of}\dots). The final result is a node, containing the
    exact quotation, and placed at the appropriate position in the tree.
    \item \textbf{Merge named entities.} The \emph{Stanford CoreNLP} library 
    performs a \emph{named entities recognition} (NER), which provide informative 
    tags in some nodes. For instance, \emph{America} is tagged \emph{LOCATION}, 
    whereas \emph{first} is tagged \emph{ORDINAL} (see figure \ref{tree_before}).
    In the preprocessing step, we merge all neighbour nodes with a same NER tag.
    In our example, we merge the three nodes \emph{United States America} into
    one single node.
\end{itemize}

\subsection{Dependency analysis}

See figure \ref{tree_after}.


\subsection{Triple production}

See figure \ref{triple_conj}.

See figure \ref{triple_tree}.


\subsection{Future work}

\subsubsection{Preprocessing}

There remains nodes which should stay together but are not merged by our module,
for instance \emph{prime minister} or \emph{state of the art}. Recognizing such words
is called \emph{Multiword Expression Processing}. The next step of the preprocessing
part of our module is to integrate an existing software which solve this problem.
